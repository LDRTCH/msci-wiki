{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14ec1392-cf44-405b-a9d0-64556b795072",
   "metadata": {},
   "source": [
    "#  Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b1ed2f-e9e7-4839-b7d8-8e08a0d7b8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import glob\n",
    "import re\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "import sys\n",
    "sys.path.append('./..')\n",
    "from src.training_utils import data_load, extract_floats, split_dataset, predict_multi_by_name, plot_violin_and_statistics\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Conv2D,Flatten,Dropout,MaxPooling2D,BatchNormalization,AveragePooling2D,LeakyReLU,GlobalAveragePooling2D,ReLU\n",
    "\n",
    "from cmcrameri import cm\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba3907c",
   "metadata": {},
   "source": [
    "# Set seed (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2036f19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_seed = 216 #choose seed (comment out if not needed)\n",
    "\n",
    "if 'fixed_seed' in locals():\n",
    "    keras.utils.set_random_seed(fixed_seed)\n",
    "    print(\"Running program with fixed seed:\",fixed_seed)\n",
    "else:\n",
    "    print(\"Running program with random seed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7ca5fc-7b31-470a-acf6-29ec5544b11e",
   "metadata": {},
   "source": [
    "# Setup GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1301b5bc-54be-4358-bb86-6d9f8671e7fd",
   "metadata": {},
   "source": [
    "First, follow instructions [here](https://gist.github.com/zrruziev/b93e1292bf2ee39284f834ec7397ee9f), or alternatively run:\n",
    "```bash\n",
    "for a in /sys/bus/pci/devices/*; do echo 0 | sudo tee -a $a/numa_node; done\n",
    "```\n",
    "We do this as a workaround for [this error](https://github.com/tensorflow/tensorflow/issues/42738):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4254e19-b9cb-4555-af86-4f539bff196d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "for device in gpu_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)\n",
    "print(tf.config.list_physical_devices('GPU'), tf.test.gpu_device_name())\n",
    "print(\"TF Version:\",tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050f798d",
   "metadata": {},
   "source": [
    "# Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c398bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predictor (model,x_val,y_val):\n",
    "    prediction = model.predict(x_val, batch_size=64)\n",
    "    print(\"Shape of prediction : \", np.shape(prediction))\n",
    "\n",
    "    plt.plot(y_val, prediction.T[0], 'o', c='k', alpha=0.25)\n",
    "    plt.plot(y_val, y_val, 'o', color='r')\n",
    "\n",
    "    print(\"Pearson's correlation coeff: \", pearsonr(y_val, prediction.T[0]).statistic)\n",
    "    plt.xlabel(\"Input turning rate\")\n",
    "    plt.ylabel(\"Predicted turning rate\")\n",
    "    plt.axis(\"equal\")\n",
    "    plt.xscale(\"log\")\n",
    "    plt.yscale(\"log\")\n",
    "    return prediction\n",
    "\n",
    "def violin_plotter (v,y_val,adjustment,legloc=\"upper left\"):\n",
    "    bins = np.logspace(-6,-1,10, base=2)*0.85\n",
    "\n",
    "    #v = prediction2.T[0]\n",
    "\n",
    "    colors = cm.batlowS(np.digitize(v, bins))\n",
    "    colors_actual = cm.batlowS(np.digitize(np.unique(y_val),bins))\n",
    "\n",
    "    fig, (ax1,ax2) = plt.subplots(nrows=2,ncols=1,figsize=(9,6),dpi=600)\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    df.insert(0, \"predicted\", v - y_val)\n",
    "    df.insert(1, \"actual\", y_val)\n",
    "\n",
    "    sns.violinplot(\n",
    "        ax=ax1,\n",
    "        data=df,\n",
    "        x=\"actual\",\n",
    "        y=\"predicted\",\n",
    "        color=\"w\",\n",
    "        alpha=0.7,\n",
    "        density_norm=\"width\",\n",
    "        linewidth=1,\n",
    "        inner=\"box\",\n",
    "        inner_kws={\"box_width\": 4, \"color\": \"0.2\"},\n",
    "        )\n",
    "\n",
    "    ax1.set_xlabel(\"Actual turning rate\")\n",
    "    ax1.set_ylabel(r\"Prediction Difference $P_{pred}-P_{true}$\")\n",
    "\n",
    "    std = []\n",
    "    means = []\n",
    "    overlap = []\n",
    "    std_div = []\n",
    "    accuracy = 5e-3\n",
    "    print (\"Prediction means and standard deviations.\")\n",
    "    for val in np.unique(y_val):\n",
    "        v_mapped = v[np.where(y_val == val)]\n",
    "        stdev = np.std(v_mapped)\n",
    "        std.append(stdev)\n",
    "        mean = np.mean(v_mapped)\n",
    "        overlap.append((val + accuracy >= np.min(v_mapped)) & (val - accuracy <= np.max(v_mapped)))\n",
    "        within_std = abs(val-mean)/stdev\n",
    "        print (f\"Actual value {val}: Average = {mean:.5f} +- {stdev:.5f}; Expected value within {within_std:.3f} stdevs of mean\")\n",
    "        std_div.append(within_std)\n",
    "\n",
    "    print(f\"With accuracy {accuracy}, overlap ratio:\", np.sum(overlap)/len(overlap))\n",
    "    print(\"(Min, Max, Avg) STD:\", np.min(std), np.max(std), np.mean(std))\n",
    "    print(\"Pearson's correlation coeff: \", pearsonr(y_val, v).statistic)\n",
    "\n",
    "\n",
    "\n",
    "    for val in np.unique(y_val):\n",
    "        v_mapped = v[np.where(y_val == val)]\n",
    "        means.append(np.mean(v_mapped))\n",
    "\n",
    "    ax2.errorbar(np.sort(np.unique(y_val)),np.abs(means-np.sort(np.unique(y_val))),yerr=(std),ecolor='black',elinewidth=0.5,capsize=3,color='purple',label=r'$|\\langle P_{pred} \\rangle -P_{true}|$')\n",
    "    ax2.plot(np.sort(np.unique(y_val)),np.zeros(np.unique(y_val).shape[0]),color='red',label='True value line',linestyle='dotted',alpha=0.5)\n",
    "\n",
    "\n",
    "    ax2.legend(loc=legloc)\n",
    "\n",
    "    counter = 0\n",
    "    for i in np.sort(np.unique(y_val)):\n",
    "        ax2.text(i,adjustment,f\"${std_div[counter]:.3f} \\sigma$\",ha=\"center\")\n",
    "        counter = counter + 1\n",
    "\n",
    "    ax2.set_xscale(\"log\")\n",
    "    ax2.get_xaxis().set_major_formatter(ticker.ScalarFormatter())\n",
    "    ax2.set_xticks(np.unique(y_val))\n",
    "\n",
    "    ax2.set_xlabel(\"Actual turning rate\")\n",
    "    ax2.set_ylabel(\"Absolute mean prediction difference\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "def mae_plotter(history,epochs,legloc='upper right'):\n",
    "    acc = history.history['mae']\n",
    "    val_acc = history.history['val_mae']\n",
    "\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    epochs_range = range(epochs)\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.plot(epochs_range, acc, label='Training MAE')\n",
    "    plt.plot(epochs_range, val_acc, label='Validation MAE')\n",
    "    plt.legend(loc=legloc)\n",
    "    plt.title('Training and Validation MAE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcab94fe-9123-4020-9df7-2e426a6749a3",
   "metadata": {},
   "source": [
    "# Import and prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c8fd6b",
   "metadata": {},
   "source": [
    "set model1 to have orientation, model2 to be monochrome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a56273-adc3-4e76-9681-90d2c2945ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all alphas: [0.016,0.023,0.034,0.050,0.073,0.107,0.157,0.231,0.340,0.500]\n",
    "#all densities: [0.05,0.10,0.15,0.20,0.25,0.30,0.35,0.40,0.45,0.50,0.55,0.60,0.65,0.70,0.75,0.80,0.85,0.90,0.95]\n",
    "x1,y,shape = data_load(alphas=[0.016,0.023,0.034,0.050,0.073,0.107,0.157,0.231,0.340,0.500], densities=[0.25],orientation=True,scrambled=False)\n",
    "x2 = np.ceil(x1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff9b6e0-d1fd-46e1-8d54-9d515df7e583",
   "metadata": {},
   "source": [
    "We have N * number of unique alpha snapshots total, we split them into training set and a validation set with the ratio 80/20:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fa57c4-74a1-456a-ac08-8483a1cef51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Orientation model:\")\n",
    "x_train1, y_train, x_val1, y_val = split_dataset(x1,y,last=int(len(x1)*0.2)) #len(x)*1 means no training, only validation!\n",
    "x_train2 = np.ceil(x_train1)\n",
    "x_val2 = np.ceil(x_val1)\n",
    "#print(\"\\nMonochrome model:\")\n",
    "#x_train2, y_train2, x_val2, y_val = split_dataset(x2,y2,last=int(len(x2)*0.2)) #len(x)*1 means no training, only validation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0775f3ca-53b6-4f50-8f1f-48de61e4fbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(nrows=1,ncols=2)\n",
    "ax1.matshow(x_val1[500],cmap=plt.get_cmap(name=\"gnuplot\",lut=5))\n",
    "ax2.matshow(x_val2[500],cmap=plt.get_cmap(name=\"gnuplot\",lut=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75d3ac4-803c-4f44-8b7d-4858b3ad757c",
   "metadata": {},
   "source": [
    "# Setup and train our models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07c0371-f8d5-4cab-b5c5-4db38020f86f",
   "metadata": {},
   "source": [
    "Workaround for dropout not working:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaaf47e6-182a-4de7-b332-d593c80ac28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextlib\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def options(options):\n",
    "  old_opts = tf.config.optimizer.get_experimental_options()\n",
    "  tf.config.optimizer.set_experimental_options(options)\n",
    "  try:\n",
    "    yield\n",
    "  finally:\n",
    "    tf.config.optimizer.set_experimental_options(old_opts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f055b9a-1e06-4038-8dbe-67df9e8eb953",
   "metadata": {},
   "source": [
    "## Setting up the models' architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e36460a-880b-4f03-b7a3-c52d5d2c8126",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_net(shape):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(filters=3, kernel_size=(3, 3), padding=\"same\", input_shape=shape))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "    model.add(ReLU())\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(filters=4, kernel_size=(5, 5), padding=\"same\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "    model.add(ReLU())\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(filters=6, kernel_size=(5, 5), padding=\"same\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "    model.add(ReLU())\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "\n",
    "    with options({\"layout_optimizer\": False}):\n",
    "        model.add(Dropout(0.1))\n",
    "\n",
    "    model.add(Dense(units=128, activation=\"relu\"))\n",
    "\n",
    "    with options({\"layout_optimizer\": False}):\n",
    "        model.add(Dropout(0.1))\n",
    "\n",
    "    model.add(Dense(units=3, activation=\"relu\"))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=1, activation=\"linear\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b5e8ab",
   "metadata": {},
   "source": [
    "# MODEL 1 (ORIENTATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ec6ec7-0da4-4c05-8382-6882dc117cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = make_net(shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a887d6d-220c-4610-bb47-d710d597d2f7",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad2606d-0e93-4a2f-9847-a7f0f65dbea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = keras.optimizers.Adam(learning_rate=0.0003)\n",
    "optimizer = keras.optimizers.SGD(learning_rate=0.005)\n",
    "model1.compile(loss='mae', optimizer=optimizer, metrics=['mae'])\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12eee402-b5c5-4ce4-a957-8ede097b3846",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Training and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84253de-f648-4980-b902-d85bcc5d720e",
   "metadata": {},
   "source": [
    "Before training, these are the \"predictions\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b8c676-25fe-41a7-af85-6d8230f38109",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction1 = model_predictor(model1,x_val1,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe3e90e-b853-4807-94cc-743f2dc8c411",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_idx = 100\n",
    "plt.matshow(x_val1[demo_idx])\n",
    "print(\"Actual: \", y_val[demo_idx])\n",
    "print(\"Predicted: \", prediction1.T[0][demo_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675dc0a7-ab76-431e-9631-982f85ef0f35",
   "metadata": {},
   "source": [
    "We can play with the architecture and see how the untrained predictions can change too."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc07d37c-1d22-464e-9070-31c63b84ed62",
   "metadata": {},
   "source": [
    "## Run the training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9607c1e7",
   "metadata": {},
   "source": [
    "### model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b726d25f-bdf0-486c-9c9b-63e2b2d8025d",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=60\n",
    "batch_size=64\n",
    "history1 = model1.fit(\n",
    "    x_train1,\n",
    "    y_train,\n",
    "    epochs=epochs,\n",
    "    verbose=True,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(x_val1, y_val)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322e9143",
   "metadata": {},
   "source": [
    "# MODEL 2 (MONOCHROME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef17bd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = make_net(shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593a1078",
   "metadata": {},
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0aaa13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(learning_rate=0.005)\n",
    "model2.compile(loss='mae', optimizer=optimizer, metrics=['mae'])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2722be",
   "metadata": {},
   "source": [
    "# Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b0f41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction2 = model_predictor(model2,x_val2,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58eac650",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(x_val1[demo_idx])\n",
    "print(\"Actual: \", y_val[demo_idx])\n",
    "print(\"Predicted: \", prediction1.T[0][demo_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dece9a21",
   "metadata": {},
   "source": [
    "## model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced528aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=60\n",
    "batch_size=64\n",
    "history2 = model2.fit(\n",
    "    x_train2,\n",
    "    y_train,\n",
    "    epochs=epochs,\n",
    "    verbose=True,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(x_val2, y_val)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e98cae5-874c-42f4-af67-e71f6a70efbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluate on test data:\")\n",
    "results1 = model1.evaluate(x_val1, y_val, batch_size=batch_size, verbose=0)\n",
    "print(\"Test loss for model1 (orientation):\", results1)\n",
    "results2 = model2.evaluate(x_val2, y_val, batch_size=batch_size, verbose=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb60c6f-b781-4461-a933-48af391a3f60",
   "metadata": {},
   "source": [
    "# Analyse training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0d37e7-ffec-4607-b5a3-00d7bc9fa153",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction1 = model1.predict(x_val1)\n",
    "print(\"Shape of prediction1 (model1 on x_val1) : \", np.shape(prediction1))\n",
    "prediction12 = model1.predict(x_val2)\n",
    "print(\"Shape of prediction12 (model1 on x_val2) : \", np.shape(prediction12))\n",
    "prediction2 = model2.predict(x_val2)\n",
    "print(\"Shape of prediction2 (model2 on x_val2) : \", np.shape(prediction2))\n",
    "prediction21 = model2.predict(x_val1)\n",
    "print(\"Shape of prediction21 (model2 on x_val1) : \", np.shape(prediction21))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ec4dd5",
   "metadata": {},
   "source": [
    "# Plot model1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d700589b",
   "metadata": {},
   "source": [
    "## Predict on xval1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ada8256-93f4-4ca8-bb1f-44a06208f648",
   "metadata": {},
   "outputs": [],
   "source": [
    "violin_plotter(prediction1.T[0],y_val,-0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c96059",
   "metadata": {},
   "source": [
    "## predict on xval2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088184d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "violin_plotter(prediction12.T[0],y_val,0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f2bde7",
   "metadata": {},
   "source": [
    "## MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f905afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_plotter(history1,epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04843a6f",
   "metadata": {},
   "source": [
    "# Plot model2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d4e15d",
   "metadata": {},
   "source": [
    "## on x_val2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edd1cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "violin_plotter(prediction2.T[0],y_val,-0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4086994",
   "metadata": {},
   "source": [
    "## on x_val1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1274e382",
   "metadata": {},
   "outputs": [],
   "source": [
    "violin_plotter(prediction21.T[0],y_val,0.07,'upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297ae509",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_plotter(history2,epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ebf16f-cd22-468c-8729-753aceda2ef0",
   "metadata": {},
   "source": [
    "# Save models (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ae8f79-1d5b-4b93-96ea-c86210a6e9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "name1 = \"daedalus5812\" #ORIENTATION MODEL\n",
    "model1.save(f\"../models/{name1}.keras\")\n",
    "name2 = \"icarus1508\" #MONOCHROME MODEL\n",
    "model2.save(f\"../models/{name2}.keras\")\n",
    "\n",
    "print(\"Name for combined .html file: \"+name1+\"-\"+name2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
